<?xml version="1.0" encoding="UTF-8"?>
<workflow-app xmlns="uri:oozie:workflow:0.2" name="${workflowName}">
    <start to="job-timestamp-properties"/>

    <action name="job-timestamp-properties"> <!-- no longer job-timestamp-properties, just producing timestamp info-->
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <main-class>com.kosei.adcreatorworkflow.hadoop.WorkflowTimestampProperties</main-class>
            <capture-output/>
        </java>
        <ok to="fetch-catalog-versions"/>
        <error to="fail"/>
    </action>

    <action name='fetch-catalog-versions'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${projectTempDataPath}/fetch-catalog-versions"/>
            </prepare>

            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.catalogs.UnprocessedCatalogVersionsMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.rest.RestResourceReducer</value>
                </property>
                <property>
                    <name>mapreduce.job.reduces</name>
                    <value>20</value>
                </property>

                <property>
                    <name>managementClientApiToken</name>
                    <value>${managementClientApiToken}</value>
                </property>
                <property>
                    <name>managementClientApiEndPoint</name>
                    <value>${managementClientApiEndPoint}</value>
                </property>
                <property>
                    <name>awsAccessKey</name>
                    <value>${awsAccessKey}</value>
                </property>
                <property>
                    <name>awsSecretKey</name>
                    <value>${awsSecretKey}</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.catalogs.data.NullInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.map.output.key.class</name>
                    <value>org.apache.hadoop.io.LongWritable</value>
                </property>
                <property>
                    <name>mapreduce.map.output.value.class</name>
                    <value>org.apache.hadoop.io.BytesWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.LongWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.BytesWritable</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${projectTempDataPath}/fetch-catalog-versions</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to="continue-if-catalogs-to-process"/>
        <error to="fail"/>
    </action>

    <decision name="continue-if-catalogs-to-process">
        <switch>
            <case to="parse-catalogs">${ hadoop:counters('fetch-catalog-versions')[RECORDS][REDUCE_OUT] gt 0 }</case>
            <default to="end"/>
        </switch>
    </decision>

    <action name='parse-catalogs'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${projectTempDataPath}/parse-catalogs"/>
            </prepare>

            <configuration>

                <property>
                    <name>managementClientApiToken</name>
                    <value>${managementClientApiToken}</value>
                </property>
                <property>
                    <name>managementClientApiEndPoint</name>
                    <value>${managementClientApiEndPoint}</value>
                </property>
                <property>
                    <name>awsAccessKey</name>
                    <value>${awsAccessKey}</value>
                </property>
                <property>
                    <name>awsSecretKey</name>
                    <value>${awsSecretKey}</value>
                </property>

                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.catalogs.ParseCatalogsMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.catalogs.ParseCatalogsReducer</value>
                </property>
                <property>
                    <name>mapreduce.job.reduces</name>
                    <value>20</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.map.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.map.output.value.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.catalogs.data.ProductItemWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.catalogs.data.ProductItemWritable</value>
                </property>
                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${projectTempDataPath}/fetch-catalog-versions</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${projectTempDataPath}/parse-catalogs</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to="convert-to-ad-creator-assets"/>
        <error to="fail"/>
    </action>



    <action name='convert-to-ad-creator-assets'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/parsed-catalog"/>
            </prepare>

            <configuration>
                <property>
                    <name>catalog.timestamp</name>
                    <value>${wf:actionData('job-timestamp-properties')['TIMESTAMP']}</value>
                </property>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.ConvertToAdCreatorAssetMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>org.apache.hadoop.mapreduce.Reducer</value>
                </property>
                <property>
                    <name>mapreduce.job.reduces</name>
                    <value>20</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${projectTempDataPath}/parse-catalogs</value>
                </property>

                <property>
                    <name>mapreduce.map.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.map.output.value.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.io.AdCreatorAssetsWritable</value>
                </property>


                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.io.AdCreatorAssetsWritable</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/parsed-catalog</value>
                </property>

            </configuration>
        </map-reduce>
        <ok to="crawl-catalog"/>
        <error to="fail"/>
    </action>


    <action name='crawl-catalog'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/image-catalog"/>
            </prepare>

            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.ByteWritableImageCrawlerMapper</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.BytesWritable</value>
                </property>

                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/parsed-catalog</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/image-catalog</value>
                </property>

            </configuration>
        </map-reduce>
        <ok to="archive-catalog"/>
        <error to="fail"/>
    </action>

    <action name="archive-catalog">
        <shell xmlns="uri:oozie:shell-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>catalog-archiver.sh</exec>
            <argument>${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/image-catalog</argument>
            <argument>${advertisersRoot}</argument>
            <env-var>HADOOP_USER_NAME=${wf:conf('user.name')}</env-var>
            <file>scripts/catalog-archiver.sh</file>
        </shell>
        <ok to="upload-catalog-meta"/>
        <error to="fail"/>
    </action>

    <action name="upload-catalog-meta">
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>

            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.UploadProductsToCategoriesMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.UploadProductsToCategoriesReducer</value>
                </property>
                <property>
                    <name>mapreduce.job.reduces</name>
                    <value>5</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.map.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.map.output.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.NullOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${advertisersRoot}/catalogs/${wf:actionData('job-timestamp-properties')['TIMESTAMP']}/parsed-catalog</value>
                </property>
                <property>
                    <name>api.token</name>
                    <value>${managementClientApiToken}</value>
                </property>
                <property>
                    <name>base.url</name>
                    <value>${managementClientApiEndPoint}</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
        <message>Failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

    <end name="end"/>

</workflow-app>
