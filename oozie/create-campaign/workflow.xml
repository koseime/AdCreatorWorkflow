<?xml version="1.0" encoding="UTF-8"?>
<workflow-app xmlns="uri:oozie:workflow:0.2" name="create-campaign-wf">
    <start to="catalog-compactor"/>

    <action name='catalog-compactor'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${compactedCatalogDir}"/>
            </prepare>

            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.CatalogCompactorMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.CatalogCompactorReducer</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.map.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.map.output.value.class</name>
                    <value>org.apache.hadoop.io.BytesWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.BytesWritable</value>
                </property>

                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${advertisersRoot}/${imageCatalogDir}</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${compactedCatalogDir}</value>
                </property>

            </configuration>
        </map-reduce>
        <ok to="ad-create"/>
        <error to="fail"/>
    </action>

    <action name='ad-create'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${campaignImageDir}"/>
                <mkdir path="${campaignRoot}"/>
            </prepare>
            <pipes>
                <inputformat>org.apache.hadoop.mapred.SequenceFileInputFormat</inputformat>
                <writer>org.apache.hadoop.mapred.SequenceFileOutputFormat</writer>
                <program>bin/ad-creator#ad-creator</program>
            </pipes>

            <configuration>
                <property>
                    <name>mapred.input.dir</name>
                    <value>${compactedCatalogDir}</value>
                </property>
                <property>
                    <name>mapred.output.dir</name>
                    <value>${campaignImageDir}</value>
                </property>
                <property>
                    <name>mapred.reduce.tasks</name>
                    <value>0</value>
                </property>
                <property>
                    <name>hadoop.pipes.java.recordreader</name>
                    <value>true</value>
                </property>
                <property>
                    <name>hadoop.pipes.java.recordwriter</name>
                    <value>true</value>
                </property>

                <property>
                    <name>layout.resource.tar</name>
                    <value>layout_resource.tar.gz</value>
                </property>
            </configuration>

            <file>${resourcesDir}/layout_resource.tar.gz</file>
            <file>${fontsDir}</file>

        </map-reduce>
        <ok to="parse-pipes-output"/>
        <error to="fail"/>
    </action>

    <action name='parse-pipes-output'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${campaignMetaDir}"/>
            </prepare>

            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.PipesOutputParserMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>com.kosei.adcreatorworkflow.hadoop.PipesOutputParserReducer</value>
                </property>

                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.map.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.map.output.value.class</name>
                    <value>org.apache.hadoop.io.BytesWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.NullWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>

                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${campaignImageDir}</value>
                </property>
                <property>
                    <name>tar.output</name>
                    <value>${campaignTarDir}</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${campaignMetaDir}</value>
                </property>

            </configuration>
        </map-reduce>
        <ok to="upload-to-S3"/>
        <error to="fail"/>
    </action>

    <action name="upload-to-S3">
        <distcp xmlns="uri:oozie:distcp-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <arg>-Dfs.s3n.awsAccessKeyId=${awsAccessKey}</arg>
            <arg>-Dfs.s3n.awsSecretAccessKey=${awsSecretKey}</arg>
            <arg>${campaignTarDir}</arg>
            <arg>s3n://${bucketName}/${campaignName}.tar.gz</arg>
        </distcp>
        <ok to="upload-campaign-meta"/>
        <error to="fail"/>
    </action>

    <action name="upload-campaign-meta">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <main-class>com.kosei.dropwizard.management.client.cli.UploadProductsToImagePaths</main-class>
            <arg>${managementClientApiEndPoint}</arg>
            <arg>${managementClientApiToken}</arg>
            <arg>${campaignVersionId}</arg>
            <arg>${campaignMetaDir}/part-r-00000</arg>
        </java>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
    <message>Failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

    <end name="end"/>

</workflow-app>