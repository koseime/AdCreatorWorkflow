To Run:
NOTE: You will need to edit the workflow.properties file for your path in HDFS, namenode, etc (see below)

export OOZIE_URL=http://localhost:11000/oozie
export PATH=<include oozie bin>

NOTE: weird hangs if history server is not running:
 ./mr-jobhistory-daemon.sh start historyserver (from hadoop install)

All paths for bin, images, and lib are from workflowroot (defined in workflow.properties):
e.g. workflowRoot=${nameNode}/user/lanceriedel/kosei/adcreator/oozie/adcreatorworkflow

You will need to copy the c++ AdCreator (ad-creator) exec to the bin directory on HDFS (see the script below)
You will need to copy the uber jar to the lib directory
The images directory is hardcoded right now.. we will need to figure out a way to have this be more dynamic by customer

There is a hack script to deploy what is needed to HDFS here:
($workspace)/oozie/adcreatorworkflow/deploy-adcreatorworkflow.sh



Command to run:

oozie job -config workflow.properties -run -DinputDir=<input catalog file>  -DoutputDir=<output directory>  -DoutputCrawlDir=<output of crawl job> -DoutputImageProcessed=<output of ad creation> -DlayoutResourceTar=<layout resources in tar.gz> -DworkflowRoot=<oozie workfow root>  -DoutputImageTar=<outputAdImages>


e.g.:
oozie job -config workflow.properties -run \
-DinputDir=kosei/adcreator/input/catalog/amazon/2014/07/28/google-input.txt \
-DoutputDir=kosei/adcreator/output/catalog/amazon/catalog-20140728 \
-DoutputCrawlDir=kosei/adcreator/output/catalog/amazon/catalog-images-20140728 \
-DoutputImageProcessed=kosei/adcreator/output/catalog/amazon/catalog-images-processed-20140728 \
-DoutputImageTar=hdfs://localhost:9000/user/chantat/kosei/adcreator/output/catalog/amazon/catalog-ads-20140728/img.tar \
-DlayoutResourceTar=layout_resource.tar.gz \
-DworkflowRoot=hdfs://localhost:9000/user/chantat/kosei/adcreator/oozie/adcreatorworkflow